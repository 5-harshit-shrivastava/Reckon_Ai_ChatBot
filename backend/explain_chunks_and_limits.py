#!/usr/bin/env python3
"""
Explain text limits, chunks, and embedding constraints
"""

import os
import sys
from pathlib import Path

# Add the backend directory to Python path
backend_dir = Path(__file__).parent
sys.path.append(str(backend_dir))

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

def explain_embedding_limits():
    """Explain embedding model limits"""
    print("ğŸ“ Embedding Text Limits & Constraints")
    print("=" * 50)

    print("\nğŸ”— Google EmbeddingGemma Limits:")
    print("  â€¢ Model: google/embeddinggemma-300m")
    print("  â€¢ Max Context Length: 2,048 tokens (~8,000 characters)")
    print("  â€¢ Output Dimensions: 768")
    print("  â€¢ Optimal Chunk Size: 400-600 characters")
    print("  â€¢ Token-to-Character Ratio: ~4 chars per token")

    print("\nâš ï¸ What Happens When Text Exceeds Limits:")
    print("  â€¢ Text gets TRUNCATED to 2,048 tokens")
    print("  â€¢ Information beyond limit is LOST")
    print("  â€¢ That's why we use CHUNKING strategy")

    print("\nğŸ“Š Other Embedding Models (for comparison):")
    print("  â€¢ Jina-v3: 8,192 tokens (~32K chars)")
    print("  â€¢ E5-Large: 512 tokens (~2K chars)")
    print("  â€¢ OpenAI Ada-002: 8,191 tokens (~32K chars)")

    print("\nğŸ’¡ Why EmbeddingGemma is Better:")
    print("  â€¢ More efficient (300M vs 1B+ parameters)")
    print("  â€¢ Better Hindi-English performance")
    print("  â€¢ FREE with no API limits")
    print("  â€¢ Optimized for production use")

def explain_chunking_strategy():
    """Explain why and how we chunk documents"""
    print("\nğŸ“ What Are Document Chunks?")
    print("=" * 50)

    print("\nğŸ¯ Purpose of Chunking:")
    print("  1. STAY WITHIN TOKEN LIMITS - Each chunk fits in 2,048 tokens")
    print("  2. IMPROVE SEARCH PRECISION - Find exact relevant sections")
    print("  3. BETTER CONTEXT QUALITY - Focused, specific information")
    print("  4. REDUCE NOISE - Avoid diluting relevant content")
    print("  5. ENABLE FINE-GRAINED RETRIEVAL - Get specific answers")

    print("\nğŸ”„ Our Chunking Strategy:")
    print("  â€¢ Chunk Size: 400 characters (optimal for EmbeddingGemma)")
    print("  â€¢ Overlap: 50 characters (maintain context continuity)")
    print("  â€¢ Smart Breaks: At sentences/paragraphs when possible")
    print("  â€¢ Preserve Meaning: Keep related content together")

    print("\nğŸ“Š Example - Long Document Chunking:")

    sample_doc = """ReckonSales provides comprehensive inventory management for businesses of all sizes.

Key Features:
1. Product Management: Add products with SKU, barcode, pricing, and category
2. Stock Tracking: Real-time stock levels with automatic alerts for low stock
3. Purchase Orders: Create and manage supplier orders with delivery tracking
4. Stock Adjustments: Handle damaged goods, returns, and manual adjustments

Getting Started:
- Navigate to Inventory â†’ Products to add new items
- Set up stock alerts in Settings â†’ Inventory Settings
- Configure suppliers in Masters â†’ Suppliers
- Use Reports â†’ Inventory Reports for detailed analysis

The system automatically updates stock levels when sales or purchases are recorded."""

    print(f"\nğŸ“„ Original Document ({len(sample_doc)} characters):")
    print(f"'{sample_doc[:100]}...'")

    # Simulate chunking
    chunk_size = 400
    overlap = 50
    chunks = []

    start = 0
    chunk_index = 0

    while start < len(sample_doc):
        end = start + chunk_size
        chunk_text = sample_doc[start:end]

        # Try to break at sentence boundary
        if end < len(sample_doc):
            last_period = chunk_text.rfind('.')
            if last_period > start + 200:  # Minimum chunk size
                chunk_text = sample_doc[start:start + last_period + 1]
                end = start + last_period + 1

        chunks.append({
            'index': chunk_index,
            'text': chunk_text.strip(),
            'start': start,
            'end': end,
            'size': len(chunk_text)
        })

        chunk_index += 1
        start = end - overlap if end < len(sample_doc) else len(sample_doc)

    print(f"\nğŸ”ª After Chunking - {len(chunks)} chunks created:")
    for i, chunk in enumerate(chunks):
        preview = chunk['text'][:80] + "..." if len(chunk['text']) > 80 else chunk['text']
        print(f"  Chunk {i+1}: {chunk['size']} chars - '{preview}'")

def show_current_chunking_stats():
    """Show actual chunking stats from database"""
    print("\nğŸ“Š Your Current Database Chunking Stats")
    print("=" * 50)

    try:
        from config.database import get_db
        from models.knowledge_base import Document, DocumentChunk
        import statistics

        db = next(get_db())

        # Get all chunks
        chunks = db.query(DocumentChunk).all()

        if chunks:
            chunk_sizes = [chunk.chunk_size for chunk in chunks]

            print(f"  ğŸ“ Total Chunks: {len(chunks)}")
            print(f"  ğŸ“ Average Chunk Size: {statistics.mean(chunk_sizes):.0f} characters")
            print(f"  ğŸ“Š Min Chunk Size: {min(chunk_sizes)} characters")
            print(f"  ğŸ“ˆ Max Chunk Size: {max(chunk_sizes)} characters")
            print(f"  ğŸ¯ Median Chunk Size: {statistics.median(chunk_sizes):.0f} characters")

            # Show size distribution
            small_chunks = len([s for s in chunk_sizes if s < 300])
            medium_chunks = len([s for s in chunk_sizes if 300 <= s <= 500])
            large_chunks = len([s for s in chunk_sizes if s > 500])

            print(f"\nğŸ“ˆ Size Distribution:")
            print(f"  â€¢ Small (< 300 chars): {small_chunks} chunks ({small_chunks/len(chunks)*100:.1f}%)")
            print(f"  â€¢ Medium (300-500 chars): {medium_chunks} chunks ({medium_chunks/len(chunks)*100:.1f}%)")
            print(f"  â€¢ Large (> 500 chars): {large_chunks} chunks ({large_chunks/len(chunks)*100:.1f}%)")

            # Show sample chunks
            print(f"\nğŸ“‹ Sample Chunks:")
            for i, chunk in enumerate(chunks[:3]):
                preview = chunk.chunk_text[:100] + "..." if len(chunk.chunk_text) > 100 else chunk.chunk_text
                print(f"  Chunk {chunk.id}: {chunk.chunk_size} chars")
                print(f"    '{preview}'")

        db.close()

    except Exception as e:
        print(f"âŒ Error getting stats: {e}")

def explain_embedding_process():
    """Explain the complete embedding process"""
    print("\nğŸ”— Complete Embedding Process")
    print("=" * 50)

    print("\nğŸ“‹ Step-by-Step Process:")
    print("  1. DOCUMENT UPLOAD")
    print("     â€¢ Large document added to database")
    print("     â€¢ Example: 2,000 character ReckonSales guide")

    print("\n  2. CHUNKING")
    print("     â€¢ Document split into 400-char chunks")
    print("     â€¢ 50-char overlap between chunks")
    print("     â€¢ Smart breaking at sentences")
    print("     â€¢ Result: 5-6 chunks from 2,000 chars")

    print("\n  3. EMBEDDING GENERATION")
    print("     â€¢ Each chunk â†’ Google EmbeddingGemma")
    print("     â€¢ Input: 400 chars of text")
    print("     â€¢ Output: 768 numbers (vector)")
    print("     â€¢ Time: ~200ms per chunk")

    print("\n  4. VECTOR STORAGE")
    print("     â€¢ 768-dimensional vector â†’ Pinecone")
    print("     â€¢ Metadata: chunk text, document info")
    print("     â€¢ Namespace: 'reckon-knowledge-base'")
    print("     â€¢ Index: 'reckon-embeddinggemma-kb'")

    print("\n  5. SEARCH PROCESS")
    print("     â€¢ User query â†’ EmbeddingGemma â†’ 768D vector")
    print("     â€¢ Pinecone finds similar vectors (cosine similarity)")
    print("     â€¢ Top 3-5 most relevant chunks returned")
    print("     â€¢ Chunks sent to Gemini Pro for answer generation")

def show_best_practices():
    """Show best practices for text limits and chunking"""
    print("\nğŸ’¡ Best Practices & Recommendations")
    print("=" * 50)

    print("\nâœ… Optimal Text Handling:")
    print("  â€¢ Keep chunks 300-500 characters for best results")
    print("  â€¢ Use overlapping chunks (50-100 char overlap)")
    print("  â€¢ Break at natural boundaries (sentences, paragraphs)")
    print("  â€¢ Preserve context - don't break mid-concept")
    print("  â€¢ Include section titles in chunk metadata")

    print("\nğŸš« What to Avoid:")
    print("  â€¢ Chunks > 600 characters (diluted meaning)")
    print("  â€¢ Chunks < 100 characters (insufficient context)")
    print("  â€¢ No overlap (loss of context continuity)")
    print("  â€¢ Breaking in middle of sentences")
    print("  â€¢ Mixing unrelated topics in one chunk")

    print("\nğŸ“Š Performance Optimization:")
    print("  â€¢ Batch embedding generation (10 chunks at time)")
    print("  â€¢ Use local model when possible (faster)")
    print("  â€¢ Cache embeddings in database")
    print("  â€¢ Monitor chunk quality scores")
    print("  â€¢ Regular embedding cleanup/updates")

    print("\nğŸ”„ Scaling Considerations:")
    print("  â€¢ Current setup: 47 chunks (optimal)")
    print("  â€¢ Recommended max: 10,000 chunks per index")
    print("  â€¢ Beyond 10K: Consider multiple indexes")
    print("  â€¢ Monitor search latency (<1 second)")
    print("  â€¢ Plan for content growth over time")

def test_text_limits():
    """Test actual text limits with your system"""
    print("\nğŸ§ª Testing Your System's Text Limits")
    print("=" * 50)

    try:
        from services.vector_search import VectorSearchService

        vs = VectorSearchService()

        # Test different text lengths
        test_texts = {
            "Short (100 chars)": "ReckonSales helps manage inventory, billing, and customer data for small businesses effectively.",

            "Medium (400 chars)": """ReckonSales provides comprehensive inventory management for businesses. Key features include product management with SKU and barcode support, real-time stock tracking with automatic alerts, purchase order management, and detailed reporting. The system integrates with GST compliance and provides multi-location inventory support for growing businesses.""",

            "Long (800 chars)": """ReckonSales provides comprehensive inventory management for businesses of all sizes. Key Features: 1. Product Management: Add products with SKU, barcode, pricing, and category 2. Stock Tracking: Real-time stock levels with automatic alerts for low stock 3. Purchase Orders: Create and manage supplier orders with delivery tracking 4. Stock Adjustments: Handle damaged goods, returns, and manual adjustments 5. Multi-location Support: Manage inventory across multiple warehouses or stores 6. Barcode Integration: Scan barcodes for quick product identification and updates. Getting Started: Navigate to Inventory â†’ Products to add new items, set up stock alerts in Settings.""",

            "Very Long (1200 chars)": """ReckonSales provides comprehensive inventory management for businesses of all sizes. Key Features include: 1. Product Management: Add products with SKU, barcode, pricing, and category information. Support for variants, bundles, and service items. 2. Stock Tracking: Real-time stock levels with automatic alerts for low stock situations. Multi-location inventory tracking across warehouses. 3. Purchase Orders: Create and manage supplier orders with delivery tracking and partial receiving capabilities. 4. Stock Adjustments: Handle damaged goods, returns, manual adjustments, and stock transfers between locations. 5. Multi-location Support: Manage inventory across multiple warehouses or stores with centralized control. 6. Barcode Integration: Scan barcodes for quick product identification and updates. Support for custom barcode generation. 7. Reporting: Comprehensive inventory reports including stock aging, movement analysis, and reorder suggestions. Getting Started: Navigate to Inventory â†’ Products to add new items, set up stock alerts in Settings â†’ Inventory Settings, configure suppliers in Masters â†’ Suppliers section."""
        }

        print("\nğŸ” Testing Embedding Generation:")

        for label, text in test_texts.items():
            try:
                print(f"\n  ğŸ“ {label}")
                print(f"     Length: {len(text)} characters")

                # Generate embedding
                import time
                start_time = time.time()
                embedding = vs.create_embedding(text)
                generation_time = int((time.time() - start_time) * 1000)

                if embedding and len(embedding) == 768:
                    non_zero = sum(1 for x in embedding if abs(x) > 0.001)
                    print(f"     âœ… Success: 768D vector, {non_zero} non-zero values")
                    print(f"     â±ï¸ Time: {generation_time}ms")
                else:
                    print(f"     âŒ Failed: {len(embedding) if embedding else 0} dimensions")

            except Exception as e:
                print(f"     âŒ Error: {e}")

        print(f"\nğŸ’¡ Key Findings:")
        print(f"  â€¢ All text lengths work (up to context limit)")
        print(f"  â€¢ Longer text gets truncated automatically")
        print(f"  â€¢ Sweet spot: 300-500 characters")
        print(f"  â€¢ Generation time increases with length")

    except Exception as e:
        print(f"âŒ Test error: {e}")

def main():
    """Main function"""
    print("ğŸ“š Understanding Text Limits, Chunks & Embeddings")
    print("=" * 60)

    # Run all explanations
    explain_embedding_limits()
    explain_chunking_strategy()
    show_current_chunking_stats()
    explain_embedding_process()
    show_best_practices()
    test_text_limits()

    print("\n" + "=" * 60)
    print("ğŸ¯ SUMMARY:")
    print("  â€¢ Google EmbeddingGemma: 2,048 token limit (~8K chars)")
    print("  â€¢ Optimal chunk size: 400 characters")
    print("  â€¢ Your database: 47 chunks, perfectly sized")
    print("  â€¢ Search works on chunk-level for precision")
    print("  â€¢ No limits on total document size (chunks handle it)")
    print("  â€¢ System automatically manages text truncation")
    print("\nğŸš€ Your chunking strategy is optimally configured!")

if __name__ == "__main__":
    main()