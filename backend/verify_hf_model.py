#!/usr/bin/env python3
"""
Comprehensive verification that HuggingFace multilingual model is working 100%
"""

def test_embedding_generation():
    """Test that embeddings are generated correctly"""
    print("üß™ Testing embedding generation...")

    try:
        from sentence_transformers import SentenceTransformer
        import numpy as np

        # Load the exact model used in your system - Google EmbeddingGemma
        model = SentenceTransformer('google/embeddinggemma-300m')

        # Test various scenarios
        test_cases = [
            ("query: How to manage inventory in ReckonSales?", "English Query"),
            ("passage: ReckonSales helps manage inventory and billing", "English Passage"),
            ("query: ReckonSales ‡§Æ‡•á‡§Ç ‡§á‡§®‡•ç‡§µ‡•á‡§Ç‡§ü‡§∞‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡•à‡§®‡•á‡§ú ‡§ï‡§∞‡•á‡§Ç?", "Hindi Query"),
            ("passage: ReckonSales ‡§á‡§®‡•ç‡§µ‡•á‡§Ç‡§ü‡§∞‡•Ä ‡§î‡§∞ ‡§¨‡§ø‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à", "Hindi Passage")
        ]

        embeddings = {}
        for text, label in test_cases:
            embedding = model.encode(text, normalize_embeddings=True)
            embeddings[label] = embedding
            print(f"  ‚úÖ {label}: {embedding.shape} dimensions")

            # Verify embedding quality
            if len(embedding) != 768:
                print(f"  ‚ùå Wrong dimension: expected 768, got {len(embedding)}")
                return False

            if np.isnan(embedding).any():
                print(f"  ‚ùå NaN values in embedding")
                return False

            if np.sum(np.abs(embedding)) == 0:
                print(f"  ‚ùå Zero embedding")
                return False

        # Test semantic similarity
        eng_query_passage = np.dot(embeddings["English Query"], embeddings["English Passage"])
        hindi_query_passage = np.dot(embeddings["Hindi Query"], embeddings["Hindi Passage"])
        cross_lang = np.dot(embeddings["English Query"], embeddings["Hindi Query"])

        print(f"\nüìä Similarity scores:")
        print(f"  English Q‚ÜîP: {eng_query_passage:.4f}")
        print(f"  Hindi Q‚ÜîP: {hindi_query_passage:.4f}")
        print(f"  Cross-language: {cross_lang:.4f}")

        # Verify semantic understanding
        if eng_query_passage < 0.3:
            print(f"  ‚ùå Low English similarity: {eng_query_passage:.4f}")
            return False

        if hindi_query_passage < 0.3:
            print(f"  ‚ùå Low Hindi similarity: {hindi_query_passage:.4f}")
            return False

        print("  ‚úÖ All similarity scores are healthy")
        return True

    except Exception as e:
        print(f"  ‚ùå Error: {e}")
        return False

def test_rag_service_integration():
    """Test that RAG service properly uses HuggingFace"""
    print("\nüîß Testing RAG service integration...")

    try:
        import sys
        import os
        sys.path.append(os.path.dirname(__file__))

        # Temporarily disable OpenAI to force HuggingFace usage
        original_key = os.environ.get('OPENAI_API_KEY')
        if 'OPENAI_API_KEY' in os.environ:
            del os.environ['OPENAI_API_KEY']

        from services.multilingual_alternatives import HuggingFaceRAGService

        # Test HuggingFace service directly
        hf_service = HuggingFaceRAGService()

        test_context = """
        ReckonSales is a comprehensive ERP system designed for small businesses.
        It provides inventory management, billing, GST compliance, and customer management.
        The system supports multiple languages including Hindi and English.
        """

        test_queries = [
            ("What is ReckonSales?", "en"),
            ("ReckonSales ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?", "hi")
        ]

        for query, lang in test_queries:
            print(f"  Testing: {query} ({lang})")

            result = hf_service.generate_response(
                query=query,
                context=test_context,
                language=lang
            )

            if result.get("success"):
                response = result.get("response", "")
                print(f"    ‚úÖ Response generated ({len(response)} chars)")
                print(f"    Model: {result.get('model', 'unknown')}")
                print(f"    Cost: {result.get('cost', 'unknown')}")

                if len(response) < 10:
                    print(f"    ‚ö†Ô∏è Response seems too short: {response}")

            else:
                print(f"    ‚ùå Failed: {result.get('error', 'Unknown error')}")
                return False

        # Restore OpenAI key
        if original_key:
            os.environ['OPENAI_API_KEY'] = original_key

        print("  ‚úÖ RAG service integration working")
        return True

    except Exception as e:
        print(f"  ‚ùå Integration error: {e}")
        return False

def test_vector_search_service():
    """Test vector search service with HuggingFace embeddings"""
    print("\nüîç Testing vector search service...")

    try:
        import sys
        import os
        sys.path.append(os.path.dirname(__file__))

        from services.vector_search import VectorSearchService

        vector_service = VectorSearchService()

        # Test embedding creation
        test_texts = [
            "ReckonSales inventory management",
            "ReckonSales ‡§á‡§®‡•ç‡§µ‡•á‡§Ç‡§ü‡§∞‡•Ä ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®"
        ]

        for text in test_texts:
            # Test query embedding
            query_emb = vector_service.create_embedding(text, is_query=True)
            print(f"  ‚úÖ Query embedding: {len(query_emb)} dims")

            # Test passage embedding
            passage_emb = vector_service.create_embedding(text, is_query=False)
            print(f"  ‚úÖ Passage embedding: {len(passage_emb)} dims")

            if len(query_emb) != 768 or len(passage_emb) != 768:
                print(f"  ‚ùå Wrong embedding dimensions")
                return False

            if all(x == 0 for x in query_emb) or all(x == 0 for x in passage_emb):
                print(f"  ‚ùå Zero embeddings generated")
                return False

        print("  ‚úÖ Vector search service working")
        return True

    except Exception as e:
        print(f"  ‚ùå Vector search error: {e}")
        return False

def main():
    """Run comprehensive verification"""
    print("üöÄ HuggingFace Model Verification")
    print("=" * 50)

    tests = [
        ("Embedding Generation", test_embedding_generation),
        ("RAG Service Integration", test_rag_service_integration),
        ("Vector Search Service", test_vector_search_service)
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\nüß™ {test_name}")
        print("-" * 30)

        if test_func():
            passed += 1
            print(f"‚úÖ {test_name} PASSED")
        else:
            print(f"‚ùå {test_name} FAILED")

    print("\n" + "=" * 50)
    print(f"üìä FINAL RESULTS: {passed}/{total} tests passed")

    if passed == total:
        print("üéâ HuggingFace model is running 100% FINE!")
        print("\n‚úÖ Confirmed working:")
        print("   ‚Ä¢ Multilingual embeddings (Hindi + English)")
        print("   ‚Ä¢ RAG response generation")
        print("   ‚Ä¢ Vector search integration")
        print("   ‚Ä¢ No API limits or costs")
        print("   ‚Ä¢ Complete fallback from OpenAI")
    else:
        print("‚ö†Ô∏è Some issues detected. See details above.")

    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)